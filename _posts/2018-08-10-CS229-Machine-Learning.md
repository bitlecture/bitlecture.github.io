---
layout: post
title:  "CS229 Machine Learning"
excerpt: "CS229自学笔记 更新至朴素贝叶斯方法"
date:   2018-08-10 06:35:54 +0000
categories: Notes
comments: true
---

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

*那一天，他终于想起来自己还有坑要填*

[CS229](http://cs229.stanford.edu/) 是斯坦福大学 **Machine Learning**的公开课

由于官网视频质量一般，此处大部分参考了[Coursera](https://www.coursera.org/)上的新版视频，由于比较基础比较入门，内容会比较简单。

#### 另外，写给可能会看到的人，本项目还在进行中，每天在不同位置都会有更新，建议现在不要继续看了



## CS229

## Statistical Learning

有一些统计学习方法的内容需要提前了解。很多概念在近年间变得十分抽象，很多旧概念旧方法在近年间突然又被翻了出来，看起来就像是什么新方法新技术一样。实际上很多名词在统计学习方法这样的领域早就十分成熟，只是在这个课程中又被称为“机器学习”而已。

实际上可以认为机器学习是统计学习的一个分支，但是基础课程中的机器学习与统计学习实际上没有什么不同，在基础应用中二者可以说是一个东西。但是两个词汇比较的话，统计学习将更偏向于经典的统计学习方法，而机器学习则是近几年比较热门的名词，总与深度学习等领域有些联系。

在这里就简单认为，统计学习是机器学习的前身，其对象是数据，主要过程是抽取特征、抽象模型、预测数据。其目的，一方面是从数据中分析得到更多的信息，另一方面也是让计算机能够更加智能化。统计学习方法主要有监督学习、非监督学习、半监督学习和强化学习，其应用覆盖模式识别、自然语言处理、计算机视觉、数据挖掘、生物医学等等各方面。需求上，一般来讲需要海量的数据，智能化的算法以及计算机技术。

有一些专有名词，受限于篇幅与时间，这里就不做详细说明了。

*看到这里，我们大概就能发现，这个和所说的机器学习实际上是相同的东西。*

所有东西都从监督学习开始。对与监督学习，我们是采用大量的有标记的数据进行训练，让模型从中学习到一个“**生成模型**”或“**判别模型**”。生成模型，是让算法学习到一个联合概率分布$$P(X,Y)$$。假设输入输出是一组在输入空间与输出空间分别独立服从某种分布的随机变量（注意，我们此时并不知道$$X$$和$$Y$$究竟服从什么样的概率分布，但是统计学习方法会假设二者服从一定的概率分布），然后通过大量数据训练，我们从中得到联合分布律的具体分布，从而能够得出

$$P(Y|X)$$

这时候模型的输出可以通过贝叶斯定理得到

$$P(Y|X)=\frac{P(X,Y)}{P(X)}$$

生成模型的收敛速度快，可以处理含隐变量的问题。

这也是很多人听了很多的一句话的具现——机器学习的理论很多都是建立在贝叶斯的工作上的。

而对于判别模型，我们主要是让算法去学习决策函数$$f(X)$$。经过对对应关系的学习，我们的模型会对对应关系进行拟合，从而得到

$$Y=f(X)$$

通过这种方式，我们就可以计算输出$$Y$$

判别模型一般用于直接预测，可以由算法设计者自行设计并使用特征，可以高效的简化问题。

在本入门课程中，示例问题采用的模型基本上都是判别模型，相比之下生成模型在较为深入的时候才会涉及。

常解决的实际问题包括**分类问题**，**回归问题**和**标注问题**。

其中还会涉及相当一部分的损失计算和验证之类的问题，遇到的时候再进行简单叙述。

## Introduction

在Stanford网站上有完整的讲义和演讲稿，可以作为参考。

本次lecture的topic是

> The Motivation & Applications of Machine Learning, The Logistics of the Class, The Definition of Machine Learning, The Overview of Supervised Learning, The Overview of Learning Theory, The Overview of Unsupervised Learning, The Overview of Reinforcement Learning 

用中文说就是

> 机器学习的动机（出现原因）与应用，定义，监督学习的概述，学习理论的概述，无监督学习的概述，强化学习概述，（课堂后勤）。

某种意义上说是一节导论课，机器学习导论。Andrew Ng，或者说吴恩达，是这个领域较为出名的人物，已经在机器学习领域进行了大约15年的研究。班级助教也都是一些相关领域的研究生，例如神经科学、计算机视觉等，可以看出Stanford的教育资源是十分顶级的。参与这个课堂的学生也来自不同系，希望使用Machine Learning解决各自领域的问题。



首先关于Machine Learning的起源，大约是早期的人工智能领域的相关工作。而在近15-20年里，ML被看作是电脑的一种正在发展的新能力。因为越来越多的实践表明，许多应用程序仅仅依靠手动编程并不能完成所有任务。举例说明的话，比如希望用电脑来读取识别手写字符数字，这个实际上很难（在后面这里会有一个基于mnist数据集的handwriting recognition，简述最简单模式识别的基本原理）。如果我想使用传统算法进行计算，那么就需要我去做特征提取与匹配（这些内容在“数字图像处理”相关课程中会有详细说明），这个过程其实相当麻烦，尤其是针对字符这种类型的数字图像；再比如我要写一个飞行器的主控，一个复杂飞行器的主控，想要使其还能适应复杂天气条件，那么软件在编写上就需要很大的工程量和实践数据。相比之下想要完成这些任务，使用一个学习算法会十分的有效。实际上目前为止，识别使用的唯一有效方法就是让计算机去学习。



而现在，学习算法也已经应用到了医学上，例如随着计算机的发展，医院会记录每一位病人的病例，并且依据巨大的数据库，将学习算法应用到医疗数据上，使得我们可能利用统计方法学习到医学的相关知识或规律。在过去的15-20年里，美国已经在建立电子的医疗数据库了。

在我们的生活中实际上我们每个人每天都有可能接触十多次学习算法相关的产品或技术，但我们并不知晓。就像我们发送邮件的时候，邮件的自动分类；通过邮局使用邮政系统的时候（美国邮政），机器自动识别邮政编码；又或者是支票上手写数字的识别，这些都是拜学习算法所赐。甚至是使用信用卡的时候，都有专门的学习算法设计来判断你是否被盗刷。

再比如当你使用一些购物或视频网站的时候，你的浏览记录也会被用来作为学习素材来供学习算法使用，网页也会依据这些信息向用户推荐合适的产品或视频。

除此之外，学习算法还应用于人类对基因组信息的挖掘等多个方向。



前面铺垫了这么多，就是希望所有人都能对机器学习产生兴趣、学会在各种问题上应用学习算法，并对相关研究产生兴趣（当然随便看看也是可以的）。



接下来就是正式内容了，首先我们假定所有人都对计算机相关的基础知识有一定了解，并有一定的编程能力，例如知道什么是复杂度，什么是数据结构。课程不会对编程有过多的要求，但是我们会编一些简单的程序。另外这个课程会涉及一部分的概率与统计的知识，学校开设的本科生概率论与数理统计已经是足够的了。另外还需要了解线性代数的相关知识，本科的线性代数课程已经绰绰有余，知道矩阵与向量和他们的基本运算即可。



那么究竟什么是机器学习呢，这个问题要追溯到1959年，机器学习被Arthur Samuel精确定义，这也是机器学习的第一个定义，大致为让机器在不被明确编程的条件下赋予计算机一定的学习的能力。他编写了一个简单的西式跳棋游戏，并让游戏AI在对抗自己的时候进行学习，久而久之这个程序甚至比他本人玩的还好。这一点甚至可以证明计算机可以完成不被明确编程的任务，即通过学习去做。

更近一些的机器学习的定义为，“a computer program is set to learn from an experience E with respect to some task T and some performance measure P if its performance on T as measured by P improves with experience E”，一个程序被认为能从经验 E 中学习,解决任务 T,达到性能度量值 P,当且仅当,有了经验 E 后,经过 P 评判,程序在处理 T 时的性能有所提升。 在上述跳棋中，E是跳棋的经验，而设置对人类获胜的游戏得分为P，通过这个定义我们就可以认为这个机器学会了跳棋。

---



首先我们开始整个课程的第一部分，**监督学习（Supervised Learning）**的相关内容。

首先举一个监督学习的例子，假如你收集到了一个数据集，用来表示附近房屋的价格，注意这个价格是出现在一个确定地理区域的。我们以房屋的面积为x轴，房屋的价格为y轴，这时可以绘制一个散点图，图像如下。

![HousingPrice](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/HousingPrice.png)

假如我也想在这个区域卖房，那么我们是否可以根据我的房屋面积来确定它的期望价格呢？实际上有许多方式，这里只说其中的一种。最简单的方式是使用一个直线对数据进行拟合，我们称其为线性回归，但是如果我希望使用其他函数对数据进行拟合，结果可能会更加精确。这种学习去预测房屋价格的问题被称为监督学习问题，因为我们需要给算法提供一个面积的数据集合一个房屋价格的参考值。

![HousingPriceLinear](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/HousingPriceLinear.png)

这是线性拟合可能的结果

![HousingPriceSquare](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/HousingPriceSquare.png)

假如使用二次函数进行拟合，就会得到这样的结果。

至于如何选择拟合函数，这在后面会讲到，另外值得一提的是，使用何种函数进行拟合，这个函数往往被称为是一个超参数（实际上是指函数的幂）。监督学习中的超参数不能通过学习来获取。

监督学习要求我们给出具体的数据集，在本问题中，就需要给出房屋价格与面积的对应数据集，通过对这个数据集的建模拟合，才能得到我们想要的结果。

这个例子是一个**回归(Regression)**问题，而回归分析是指企图去预测一个变量是**连续值**的输出值。

还有一类监督学习问题叫做**分类(Classification)**问题，这一类问题的变量往往是离散的，例如，你收集了一份乳腺肿瘤的数据集，我们需要一个算法去判断一个肿瘤是否为恶性肿瘤，因此我们收集了关于这个乳腺肿瘤问题的诸多信息，假设我们只通过大小来判断，那么我们的问题就是，假设输入参数为肿瘤大小，输出结果为是否恶性。这个结果只能是0或1的，这时的问题就是分类问题。这时Y轴的坐标就是0或1，即表示肿瘤是良性还是恶性。这还是一个典型的二分类问题。

![BreastCancer](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/BreastCancer.png)

假设收集到的数据如上，我们对这个问题进行建模的时候就会发现这是一个分类问题。

当然分类问题的类别往往不只是一类。分类问题的类别还可以是很多类别，这一些在感知机等地方应该已经学到过了，其中感知机是线性分类器，而利用机器学习的分类器就未必是线性分类器了。这个内容有机会会单独说一下（或者补在下面）。

对于二维的分类问题，往往会将数据画成这样

![BreastCancerII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/BreastCancerII.png)

对于更多维度的分类问题，会有不同的表示方式。

当我们遇到一位用粉色标出的病人时，我们就可以利用我们的模型确定，这个肿瘤是良性的（但是实际结果还是要依据医生的判断。正规的判断流程必须要有经验丰富且接受过专业培训的医师进行参与，本视频系列的作者、讲师吴恩达前些时间带领的团队在医学影像诊断肿瘤的实验中，并没有成功建立一个识别率可以替代专业医师的模型）。

![BreastCancerIII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/BreastCancerIII.png)

当然上面的分类器也只是一个例子，因为实际上对于医学影像进行识别的过程往往需要更多的参数来辅助分类器进行诊断，例如块厚度，肿瘤细胞的大小形状的一致性等等。特征量往往会很多，这对于传统的线性分类器来说也会降低其精准度。不过这里要先从支持向量机说起，这个简单的算法可以让计算机理论上处理无穷多的特征。

以上是**监督学习**的相关概述，以下是**无监督学习（Unsupervised Learning）**的相关内容。

当我们的样本数据集没有被标识哪些输入应当对应哪些输出，即没有标签的数据，例如

![Unsupervised](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/Unsupervised.png)

我们的问题就成为了，“假如我给定了一个数据集，你是否能够应用学习算法发现数据集中的某些结构或规律”。

对于上述图像的数据集，我们可以得到的信息也有不少，例如我们知道这个数据集可以组成两组**聚类（cluster）**。实际上聚类算法就是典型的无监督学习方法。聚类算法的应用很广，例如新闻的分类推荐，医学上不同基因组个体的分类，计算机集群管理、社交网络分析、天文数据分析、市场分配管理等。在算法执行前，我们并没有告诉程序要如何进行聚类，所有的聚类都是算法在无监督条件下完成的。

我们在电子领域常见的**鸡尾酒会（Cocktail Party）算法**，即把两个相互叠加的音频相互分离的算法，实际上也是一种无监督学习算法。如果我们只关注实现，而不关心算法要如何去实现的时候，实际上这是一个较为简单的工作，只需要一行代码就能解决

```matlab
[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x');
```

这实际上是一条Octave语句，在简单的考虑实现效果的条件下可以对Octave，MATLAB或Python等语言进行了解。Octave与MATLAB语句较为相似，易于移植。对于学习过程，吴恩达推荐了Octave。实际上目前条件下使用Python也是较为简单的。当我们用这类语言确定可以实现后，我们就可以将其移植到C++等较快的编译平台上去执行。

## Linear Regression

线性回归是什么？这都不知道的话还是回去学数学比较好。初中和高中数学都学过使用最小二乘法解决线性回归的问题，这里不再赘述。

线性回归是很多初学者的第一课。吴恩达老师仍然使用了房价数据集，此处可能做调整。用一个曾经使用的例子来看，假设散点是这样的

![HousingPrice](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/HousingPrice.png)





那么我们似乎可以认为，这些散点可以用一条直线来拟合，即线性回归。我们将拟合直线绘制到平面上，效果如图。

![HousingPriceLinear](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/HousingPriceLinear.png)





---



我们假设整个数据集拥有的样本总数为$$m$$个，输入特征量为$$x$$，输出变量为$$y$$，那么可以使用$$(x,y)$$这种形式来表示一组训练样本。对于整个数据集中的第$$i$$个数据，此处将用$$(x^{(i)},y^{(i)})$$来表示(方便起见有时候也会用$$(x_i,y_i)$$表示一个训练样本)。

这时我们手里会有一个训练集，包括了$$x$$和对应的标签$$y$$。这时将训练集输入给我们的学习算法，学习算法将输出一个函数$$y=h(x)$$，描述了$$y$$与$$x$$的对应关系。这里用$$h$$是代表了$$hypothesis$$，实际我个人习惯还是写成$$f$$。对这个输出函数输入一个$$x$$，这个函数将给出一个拟合的$$y$$。

![LinearRegressionI](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/LinearRegressionI.png)

对于线性回归的关系，我们将表示$$h$$为

$$h_{\theta}(x)=\theta_0 +\theta_1x$$

其中$$\theta_i$$是参数。

当然这个结果可以不是线性函数，但此处只对线性回归进行说明。

## Cost Function

首先介绍统计学习中的损失函数和风险函数。

所谓的损失函数，代价函数，都是相同的意思，用来度量某一个过程中的错误程度，一般会使用非负函数。我们在优化过程中一定会希望错误程度越小越好，为了方便的评价错误程度，完全采用非负函数进行度量就可以，因为最小值就是$$0$$，因此只要让这个错误程度尽可能接近$$0$$就可以了。一般的我们记为

$$L(Y,f(X))$$

常见的损失函数有0-1损失、平方损失、绝对损失、对数损失（对数似然损失）函数等，损失函数值越小，我们认为模型就越好（当然也是存在例外的，这个在后面会说到）。我们会计算一个损失函数的期望，即

$$R_{exp}(f)=E_P[L(Y,f(X))]=\int\limits L(Y,f(X))P(x,y)dxdy$$

这个期望叫做**风险函数**或**期望损失**。

一般来讲我们的模型学习的目的就是选出期望损失最小的模型，但是实际上，在学习完全完成之前我们并不知道联合分布律$$P(X,Y)$$所以这个计算是不能实现的，也不能根据这个来筛选最好的模型。工程上最常用的解决方式就是近似。所以我们采用

$$R_{emp}=\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))$$

这个叫做**经验风险**，我们常采用经验风险做近似。根据大数定律，我们可以知道$$N$$极大的时候二者是趋于相等的，但是实际中$$N$$的大小并不一定很大，近似效果也没有那么好。

既然选定了采用经验风险代替风险函数进行近似，那么就要对经验风险进行最小化处理，模型的求解就成为了一个最优化问题。当样本容量很小的时候，经验风险的最小化学习效果可能出现偏差，这是下面会说到的过拟合问题，这时候我们可能会对优化项增加一个正则化项，称其为**结构风险**。

$$R_{srm}=\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))+\lambda J(f)$$

这个正则化项中，$$\lambda$$是一个非负系数，$$J(f)$$是定义在假设空间上的一个泛函，代表模型$$f$$的复杂度，是复杂度的单调增加函数。正则化项对应模型的先验概率。

接下来才是机器学习中的相关内容，虽然十分相似。



代价函数的含义为A function that can measure the accuracy of our hypothesis function，即可以衡量我们的数据与拟合情况的误差的函数。 

代价函数可以让我们筛选出最适合拟合我们数据的直线。按上文所说，我们已经有了数据，也知道我们的直线模型$$h$$是什么样子的。接下来需要构建合适的损失函数使得拟合结果最为准确。

想要获得与数据最为接近的直线，首先我们需要知道误差是什么。按照一般最小二乘法的思路，拟合函数与我们数据的误差为

$$\widehat{e}=\widehat{y}-y$$

此处可以写为

$$cost=h_\theta(x)-y$$

我希望我得到的结果与数据差异尽量小，就需要优化这个代价函数，使得这个代价函数最小，即求解$$min\{\sum\limits Cost\}$$

常用的代价函数很多，均方差函数（Square Error）用的很多，即

$$cost_i=(h_\theta(x_i)-y_i)^2$$

至于这里为什么要使用$$(\Delta y)^2$$作为损失函数，后面会做介绍。



首先，明确我们需要最小化误差，所以需要计算

$$minimize\{ \frac{1}{2M}\sum\limits_{i=1}^M(h_\theta(x_i)-y_i)^2 \}$$

即需要对 “每个数据位置与我们拟合直线的垂直距离的平方和的平均值的一半” 做最小化处理。

在这个计算过程中，我们的目的是计算出合适的参数$$\theta_0 $$和$$\theta_1$$。

为了方便理解，我们可以认为这个函数是关于参数变量$$\theta_0 $$和$$\theta_1$$的二维函数，因此代价函数可以绘制成一个二维曲面，我们需要做的就是寻找这个二维曲面的全局最小值。

此时我们定义**代价函数**为

$$J(\theta_0,\theta_1)= \frac{1}{2M}\sum\limits_{i=1}^M(h_\theta(x_i)-y_i)^2$$

这种形式的代价函数有时也被叫做平方误差函数，其前面的系数对结果往往没有直接影响（但是在程序设计过程中有可能因为系数大小问题而出现报错）。除此之外，实际上还有许多其他代价函数可以在机器学习的过程中进行选择，例如*交叉熵*（详见《信息论》）。



现在我们需要求解代价函数$$J(\theta_0,\theta_1)$$的最小值了。

为简单起见，我们先假设$$\theta_0=0$$，此时原问题退化为求解代价函数$$J(\theta_1)$$的最小值。一元函数的最小值相比之下会更简单一些。由于在选择代价函数的时候我们选择了均方差损失函数，因此我们能够得到的最小值就是0，这对于编程实现来说更加容易一些。这时的代价函数随变量$$\theta_1$$的变化可以直观的标在平面直角坐标系（只有一个参变量）。按照吴恩达老师给出的示例，其结果应该如图

![CostFunctionI](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/CostFunctionI.png)

当然对于不同的优化问题和代价函数，其结果都是不同的。当我们的代价函数在合适的$$\theta_1$$下能够取到最小值的时候，我们认为这就是在我们代价函数的限制下取得了最优解。由于不同的代价函数在取得最小值时的参数不尽相同，因此不同的代价函数的最优解是不同的，典型的例子就是最小二乘法中取$$(\Delta y)^2$$和$$(distance)^2$$时，结果都是不同的，但是实际应用上我们都以我们的需求规定最合适的代价函数，并认为按照我们代价函数取得的最优解就是问题的最优解。



当然实际问题要远比单变量问题要复杂，线性回归问题就往往是两个变量。当我们的$$\theta_0$$不是$$0$$的时候，问题就成为了求解二维曲面上的最小值点。学过《高等数学》或同类课程我们会知道求解复杂二维曲面上的最小值问题其实有一定难度。当然这个问题中，二维曲面只有最高二次幂，因此得到的图形可能并不是那么复杂，例如吴恩达给出的图形为

![CostFunctionII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/CostFunctionII.png)



人们也常用轮廓图（contour plot, a graph that contains many contour lines）来表现一个二维曲面，这看起来更像一个等高线。当我们接近这一组“等高线”的最低端时，我们认为此时就取到了损失函数的最小值，

![CostFunctionIII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/CostFunctionIII.png)

问题复杂的时候，轮廓图也会变得十分难看。此时计算最优解的过程也变得较为复杂，因此我们选择使用编程实现。

## [Gradient Decent](https://en.wikipedia.org/wiki/Gradient_descent)

**[梯度](https://en.wikipedia.org/wiki/Gradient)下降法**常用与解决最小值的问题。有时也叫牛顿法，广泛应用在众多领域的优化问题上。前面提到解决最小化代价函数的问题，这里要使用梯度下降法来求解。

我们现在有一个代价函数$$J(\theta_0,\theta_1)$$，并且需要求他取到最小值时的$$\theta_0$$和$$\theta_1$$。但是我们并不知道这两个参数的值是什么，所以我们会首先给他们初始化一个值，这个值可以是0，也可以是随机数。我们在梯度下降算法中，会根据一定的规则对两个参数的值进行调整，直到两个参数落入最优解（有可能是全局最优解，也有可能是局部最优解）位置时停止。完整的过程如下：

首先假如我们的代价函数绘制的二维图像和初始化的$$\theta_0$$和$$\theta_1$$如图所示

![GradientDecentI](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/GradientDecentI.png)

现在我们需要搜索规定邻域内（在代码中会说明）的最小值。如果需要让算法速度达到最快，就需要按照梯度（反）方向进行移动，如图

![GradientDecentII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/GradientDecentII.png)

这样我们就更新了参数$$\theta_0$$和$$\theta_1$$，使得代价函数的值缩小。在新的位置继续按梯度（反）方向进行下降，并且循环下去，我们就会得到最低点

![GradientDecentIII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/GradientDecentIII.png)

不过这样的算法有时会导致得到局部最优解，而非全局最优解（实际上十分常见），如图

![GradientDecentIV](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/GradientDecentIV.png)

这是这个算法的特点之一。数学上，我们定义梯度下降如下

$$\theta_j:=\theta_j - \alpha \frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)$$

此时$$j=0, 1$$，并且请注意，在每一次做如上操作时，应当在整个周期都计算完毕后才更新参数。

这一过程将不断循环直到满足预计的收敛条件。

等式中，$$\alpha$$被称为学习速率，在梯度下降过程中他决定了每一次下降过程中的步长。这个微分项实际上就是我们说的梯度。

$$\alpha$$的取值的问题，在简单问题上一般会取为一个很小的固定值，但是会遇到一些问题，例如结果无法达到最为精确。因为每一次做梯度下降的时候，参数总会按照$$\alpha$$的大小进行变化，因此可能并不能将参数的最精确值计算出来。在实际操作中，实际上常采用的是随下降过程逐渐缩小$$\alpha$$的方法，例如每一定次数的梯度下降后就修改$$\alpha$$为之前的$$90\%$$。随着算法进行，到收敛时我们就能获得一个更为精确的值。

## Cost Function + Gradient Decent + Linear Regression

然后我们将两个内容结合在一起，就得到了下面的式子

$$\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)=\frac{\partial}{\partial\theta_j}\frac{1}{2M}\sum\limits_{i=1}^M(h_\theta(x_i)-y_i)^2$$

即

$$\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)=\frac{\partial}{\partial\theta_j}\frac{1}{2M}\sum\limits_{i=1}^M(\theta_0+\theta_1x_i-y_i)^2$$

那么，每次梯度下降时参数的更新就可以写作

$$\theta_0:=\theta_0 - \alpha \frac{1}{M}\sum\limits_{i=1}^M(\theta_0+\theta_1x_i-y_i)$$

$$\theta_1:=\theta_1 - \alpha \frac{1}{M}\sum\limits_{i=1}^M(\theta_0+\theta_1x_i-y_i)*x_i$$

(前面提到过，在计算出$$\theta_0$$的时候不要直接修改他的数值，而是要等待这一个循环中所有计算都完成后再更新参数的数值。)

接下来我们使用一组数据进行简单的测试，代码将在Python中完成。

程序代码[点此下载](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/tempsrc/LinearRegression.py)

以上将数据进行绘制。我们采用的是均匀分布的$$x$$与正态分布的噪声。

为了拟合直线，我们采用梯度下降的方法，按照前面介绍的方法，程序如上所述。

这个方法一般被称为“**Batch** Gradient Decent（批量梯度下降）”，因为在每一次的梯度下降中我们都需要用到所有数据（每一次都使用所有数据进行求和）。在应用中梯度下降法的种类很多，后面也会逐渐接触。

线性回归的算法还很多，梯度下降法往往并不是最优先考虑的方法，这里只是一个简单介绍。在线性回归中还有一种正规方程法（Normal Equation），这个方法在后面也会提及，但是梯度下降法会在更大量的数据中表现出更优秀的效果。

## Linear Algebra

CS229少量提及一部分线性代数，这一部分可以参考课本进行复习。



## Multiple Features

 介绍一种可以用于多变量和多特征量的线性回归方法，使用矩阵乘法。

假设在房价预测的问题上，我们有了更多的信息参数可以使用，例如房间数、层数、使用时间等额外的参数。

这时在表示不同的参变量时，我们采用$$x_i$$的方式，例如房间数为$$x_1$$，层数为$$x_2$$，已用时间为$$x_3$$等。这时在描述每一个样本时我们不得不使用$$x_i^{(j)}$$等方式进行，当然我们也可以使用矩阵的描述方法进行描述。

由于变量数目的增加，我们将使用新的方式描述线性回归的方程，即

$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\theta_4x_4$$

如果我们认为$$x_0=1$$，我们就可以写作

$$h_\theta(x)=\sum\limits _{i=1}^4\theta_ix_i$$

或者说，如果我们认为$$x$$可以看作是由多个变量组成的向量，即

$$ x=\left[ \begin{matrix} x_0  \\ x_1  \\ x_2 \\ x_3 \\ ... \\ x_n  \end{matrix} \right] $$ 

参数同理

$$ \theta=\left[ \begin{matrix} \theta_0  \\ \theta_1  \\ \theta_2 \\ \theta_3 \\ ... \\ \theta_n  \end{matrix} \right] $$ 

那么就可以将拟合的抽象直线方程写作

$$h_\theta(x)=\theta^Tx$$

这是向量内积的表现。这时我们就可以描述多变量和因变量的线性关系了，这被叫做多元线性回归，因为每一个变量对结果的影响都是线性的。

由于这种变化，前面对代价函数的描述也会发生改变，即

$$J(\theta)= \frac{1}{2M}\sum\limits_{i=1}^M(h_\theta(x^{(i)})-y^{(i)})^2$$

在梯度下降的时候，梯度项也会改变

$$\theta_j:=\theta_j - \alpha \frac{1}{M}\sum\limits_{i=1}^M(h_\theta(x^{(i)})-y^{(i)})*x_j^{(i)}$$

这里自己求导推一下记得更清楚（

## Feature Scaling

特征量的缩放。假设我们只有两个变量，即$$x_1$$和$$x_2$$，那么如果我们把两个变量的范围都放缩到一个合理的小范围内，训练时的收敛速度也会更快。我们在处理特征量缩放的时候往往会将它们控制到

$$-1\le x \le1$$

当然在较为接近的小范围内也是可以接受的。

在进行特征量缩放的时候也经常会做一个**均值归一化(Mean Normalization)**的操作。假设变量$$x_i$$的均值为$$\mu_i$$，我们会先将其替换为$$x_i-\mu_i$$，这样得到的新变量就可以很轻易的控制到一个关于0对称的区间内。一般是取

$$\frac{x_i-\mu_i}{Range}$$

这个Range是数据集中的最大值与最小值的差。

当然这样做只是为了梯度下降法能更快一些。

## Learning Rate

首先需要确定梯度下降是否在正确运行，这时候我们需要确定代价函数的值是否在减小。随着迭代次数的增加，对代价函数的梯度下降优化参数应当会导致代价函数不断减小。只要每过一定时间对代价函数值进行测试，我们就能确定梯度下降在正确运行。

当每一次迭代过程中代价函数减少的比例低于$$\epsilon=10^{-3}$$的时候（这个值可以根据实际情况来判断），我们通常认为训练结束，结果已经收敛。

如果结果并不收敛，我们经常会调整学习速率$$\alpha$$，使得每一次改变的步长都减小一些。前面说过当学习速率$$\alpha$$过大的时候，结果往往不易收敛（甚至会导致不收敛），当学习速率过小的时候，收敛速度往往会很慢。实际中常常采用渐渐增加的方式对学习速率进行测试，例如从$$0.001$$开始，如果收敛很慢就增加到三倍，$$0.003$$，如果仍然很慢，就增加到$$0.01$$，以此方式继续。当然起点还可以更小。

## Features and Polynomial Regression

特征与方法选择。

仍然对房屋价格进行假设，我们现在研究房屋沿街长度和沿街深度与房价的关系，假设建立线性关系如下

$$h_\theta(x)=\theta_0+\theta_1*frontage+\theta_2*depth$$

但是我们在学习的过程中可以不采用$$frontage$$和$$depth$$这两个变量作为特征，我们可以采用其他变量，换言之可以用其他方式探明房屋价格与什么有关。

我们假设变量为

$$x=frontage*depth$$

这里可以认为$$x$$是土地面积。这样我们就可以将模型写成

$$h_\theta(x)=\theta_0+\theta_1x$$

有时采用新的特征确实会取得更好的模型。假设我们还是在使用原房屋价格数据集，这个数据集的点可以使用线性关系来拟合，但是也有可能使用非线性模型来拟合。当线性不满足要求的时候，我们可能会采用二次模型或三次模型，也有可能是更高阶次的模型。这时模型可以变成

$$\begin{align*}  h_\theta(x)&=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3 \\ &= \theta_0+\theta_1x+\theta_2x^2+\theta_3x^3  \end{align*}$$

其中$$x$$是前面定义的面积。要注意当$$x$$做指数处理的时候，它的范围也会有显著改变，因此要注意**特征量的归一化**。

至于为什么要采用多项式回归的方法，如果学过《高等数学》或者《微积分》的话，我们应当会熟悉级数。基本初等函数都可以展开成为幂级数，因此多项式回归一定意义上可以代替（而不是取代）部分回归方式。

幂级数也不一定要采用整数幂。实际上采用$$\frac{1}{2}$$次幂也是符合要求的。

## Normal Equation

前面都在介绍如何使用梯度下降的方法进行线性回归，实际上还有其他的在某些条件下效果较好的算法。

假如此时的代价函数是一个一元函数，经过某种分解后我们可以写成如下形式

$$J(\theta)=a\theta^2+b\theta+c$$

我们在求解最小值的时候，除了采用梯度下降的方法以外，还可以采用求导的方法（这在中学期间我们就应该学习过了）。我们对代价函数求导，使代价函数的导数为0，我们就会得到驻点。

当我们的代价函数并不是一元函数的时候，例如

$$J(\theta_0,\theta_1,...,\theta_m)=\frac{1}{2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2$$

根据《高等数学》等基础数学教材的内容，我们知道可以对每一个参数$$\theta_j$$进行求（偏）导数，并将它们全部置零。这时候我们就可以得到代价函数的最小值。但是对于这么多变量的计算来说，最终的偏导数可能会很多并且很复杂，我们需要使用一些方法对这个过程进行等价。

假设我有四组数据如下

| $$x_0$$ | Size-$$x_1$$ | Rooms-$$x_2$$ | Floors-$$x_3$$ | $$x_4$$ | $$y$$ |
| ------- | ------------ | ------------- | -------------- | ------- | ----- |
| 1       | 2104         | 5             | 1              | 45      | 460   |
| 1       | 1416         | 3             | 2              | 40      | 232   |
| 1       | 1534         | 3             | 2              | 30      | 315   |
| 1       | 852          | 2             | 1              | 36      | 178   |

我可以将所有数据都放到矩阵$$X$$和$$y$$中，即

$$ X=\left[ \begin{matrix} &1 \ &2104 \ &5 \ &1 \ &45  \\ &1 \ &1416 \ &3 \ &2 \ &40  \\ &1 \ &1534 \ &3 \ &2 \ &30 \\&1 \ &852 \ &2 \ &1 \ &36  \end{matrix} \right] $$ 

$$ y=\left[ \begin{matrix} 460  \\ 232 \\ 315 \\ 178 \end{matrix} \right] $$

回归的时候我们采用

$$y=X\theta$$

那么

$$\theta=(X^TX)^{-1}X^Ty$$

这里甚至不需要使用特征量的归一化。

对于梯度下降法来说我们可能需要选择合适的学习速率，需要多次迭代，但是正规方程法都不需要。但是对于较多特征量的时候，梯度下降法效果会更好，即使有百万特征量，但是对矩阵进行转置和逆运算的过程此时就变得很慢($$O(n^3)​$$)。当特征量超过$$10^4​$$的时候，梯度下降法往往是最优解。

>当然我们会遇到一类情况，即$$X^TX$$不可逆的情况。这时我们就不能计算$$(X^TX)^{-1}$$。这类矩阵被称为奇异矩阵（当然这个名字并没什么卵用）。但是如果我们使用Octave或者MATLAB计算的话，他们却不会报错，反而会按照要求将程序执行，得到一个看似“正常”的结果。这个逆矩阵的过程也叫作“伪逆矩阵”。出现不可逆的情况往往会是采用了两组或多组意义相同、数值也呈线性关系的数据，这样会导致矩阵不满秩，从而不可逆。还有一类情况是采用的数据维度过多（特征过多），但是却无法提供相同数量级的数据，这时候矩阵也是不可逆的，例如我们使用$$10$$组数据去描述$$100$$个特征，这显然数据量十分不足。不过如果希望使用$$10$$组数据描述$$100$$个特征，我们可以使用一个叫做正则化的手段删除一部分特征，当然也有其他解决方案对应较小数据集的方案会在后面介绍。

## Remark I

吴恩达老师一直在推荐Octave软件的编程，我实际上还是比较坚定Python的使用的。所以就不进行Octave的学习和笔记了。当然要说明，像Octave这样的高级语言，我们容易进行模型的建立和最初始的编程，至于最终实现仍然要使用C++等底层编译语言，但是这些过程都可以使用Python来完成，因为Python可以像MATLAB、Octave那样搭积木，也可以调用C++的被封装的底层来进行运算（虽然比纯C++实现要慢）。当前使用Python的入门还是较多的。

另外老师在Coursera中演示的功能都可以使用Python进行实现。



## Classification

最简单常用的分类算法是逻辑回归。常见的分类问题有垃圾邮件分类器、医学诊断分类器、实体交易是否欺诈等。在这些问题上，我们的分类结果往往是$$y\in \{0,1\}$$，其中$$0$$一般代表否定，$$1$$一般代表肯定，这样的分类是一个二分类问题。后面也会涉及多分类问题。

假设我们得到了一个数据集，其中

![ClassificationI](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/ClassificationI.png)

我们首先可能尝试使用线性的方法对它进行尝试，即

![ClassificationII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/ClassificationII.png)

我们可以说，当直线上取值超过$$0.5$$的时候，我们预测$$y=1$$，否则预测$$y=0$$。这不失是一种分类方法。我们注意到，这个数据集目前来看还是十分OK的，但是如果有一个数据他是远高于目前数值的，我们会如何处理呢？

对于$$x$$坐标，是肿瘤大小的数值，我们只见过大小是正数的肿瘤，而没见过是负数的。而且在实际中，癌症肿瘤大小上限与良性肿瘤大小上限相比，要大得多。因此我们仍然采用线性回归方法进行分类的话，结果就会出现较大差错，将较小的癌症肿瘤也计入良性肿瘤中。

为了解决这样一个问题，我们一般会采用**逻辑回归**的方式进行分类，虽然是一个分类问题，但是却起名叫“回归”。对于逻辑回归，我们的$$h$$函数应满足

$$0 \le h_\theta(x) \le 1$$

那么哪里可以找到这样的函数呢？

我们可以对$$h_\theta(x)$$做一定的变换，得到

$$h_\theta(x)=g(\theta^Tx)$$

其中

$$g(x)=\frac{1}{1+e^{-x}}$$

这个函数$$g(x)$$也被称为Sigmoid函数或Logistic函数，图像如下

![Sigmoid](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/Sigmoid.png)

上渐近线$$y=1$$，下渐近线$$y=0$$，值域为有限域。

这时我们的假设函数就可以较为容易的拟合我们的数据，还不易出现线性拟合的错误。在这里，由于输出的范围是0到1，所以我们可以认为输出结果是一个$$y=1$$的概率。

这时我们的假设函数就可以写成

$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$$

## Decision Boundary

决策边界。当我们看到Sigmoid曲线的时候我们容易知道，当传统的Sigmoid曲线的输入小于0，输出就是小于0.5的，这时就会输出倾向于0的概率，否则会输出一个倾向于1的概率。假设我们有一个如图所示的数据集

![DecisionBoundaryI](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/DecisionBoundaryI.png)



此时的假设函数就是

$$h_\theta(x)=g(\theta_0+\theta_1x_1+\theta_2x_2)$$

假设我们已经做好了拟合，结果是

$$\theta=\left[ \begin{matrix} -3 \\ 1 \\ 1   \end{matrix} \right]$$

写成我们熟悉的形式就是

$$-3+x_1+x_2 \ge 0$$

条件下会输出一个倾向于$$y=1$$的概率。

而这个区域在图像中表现出来就是

$$x_1+x_2 \ge 3$$

即

![DecisionBoundaryII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/DecisionBoundaryII.png)

其中在右上方部分的区域就是我们求解的区域。

那么对应的，左下区域这部分就是我们预测$$y=0$$的区域。那么我们绘制的这条洋红色的，将$$y$$的预测值分隔开的这条线，就是我们所说的“决策边界（Decision Boundary）”。

有时候我们的数据集并不是这么友好的，例如有的时候数据集是这样的

![DecisionBoundaryIII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/DecisionBoundaryIII.png)

对这样的数据集要如何应用逻辑回归呢？我们前面的多项式回归说过可以添加高阶项来拟合，那么我们假设添加两个额外特征如下

$$h_\theta(x)=g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)$$

那么我们就会有五个参数来进行拟合。经过合适的训练（后面会讲），我们可能得到的结果是

$$\theta_0=-1$$，$$\theta_1=\theta_2=0$$，$$\theta_3=\theta_4=1$$

那么得到的决策边界就是

$$x_1^2+x_2^2=1$$

显然我们通过前面学到的使用更加复杂的特征得到了更为精准的决策边界，使用二次项避免了使用直线进行直接拟合。

实际遇到的问题中结果可能会更加复杂，我们拟合的形状也有很多的可能性，这时候可能需要更多的高次项来帮助我们得出决策边界。

## Cost Function II

我们用同样的方式定义训练集，每个样本都可以写成$$(x^{(i)},y^{(i)})$$的形式。注意由于是逻辑回归，我们的标签$$y \in \{0,1\}$$。

假设函数为

$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$$

那么我们应该如何对这个模型进行拟合呢？

如果还是采用之前的代价函数（均方差）进行梯度下降求最小化，我们就容易发现，这时的优化目标$$J(\theta)$$是非常难看的——他有很多局部最小值（极小值点）而且分布十分复杂，使用梯度下降法很难对其进行优化。我们称这个$$J(\theta)$$是一个non-convex function。因此我们需要换一个代价函数，使结果成为一个较容易优化的函数，这样就容易收敛到全局最优解。

我们的答案是这样的

$$Cost(h_\theta(x),y)=\begin{equation}\left\{\begin{array}{lr} -log(h_\theta(x),& if\:y=1 \\-log(1-h_\theta(x)),& if\:y=0  \end{array}\right.\end{equation}$$

看起来十分复杂，不妨绘制图像。

当$$y=1$$时，我们绘制结果如图

![CostFunctionIV](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/CostFunctionIV.png)

带入特殊值得到，当$$h_\theta(x)\rightarrow 1$$的时候，代价函数值很小，符合预期，反之代价函数的值趋近于无穷大，满足条件。

当$$y=0$$时，我们绘制结果如图

![CostFunctionV](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/CostFunctionV.png)

同样的我们容易验证这个代价函数符合预期要求，同时也容易验证，当我们对$$y$$进行分类讨论的时候，$$J(\theta)$$会是一个易于优化的函数。

接下来要用梯度下降法进行拟合。上面已经写过了代价函数，但是那个形式是需要两行才能描述损失函数的意义。这样不利于进行梯度下降，所以我们需要对这个形式进行改写。这时候利用一点trick就可以将原形式改写成

$$Cost(h_\theta(x),y)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))$$

*仔细想想这个也是我在高中证明题中常用技巧呢（笑）*

手动带入0和1检验一下就能看出来这样是对的了。

随意损失函数就可以写成

$$J(\theta)=\frac{1}{m}\sum\limits_{i=1}^m[-y^{(i)}log(h_\theta(x^{(i)}))-(1-y^{(i)})log(1-h_\theta(x^{(i)}))]$$

这个代价函数实际上可以从最大似然估计的方法推导，这个在本次课程中并不涉及。只是提及，这个方法可以让优化过程变得简单。所以要找到最小化损失函数的方法。前面说到使用梯度下降法进行优化，那么求解梯度得到

$$\theta_j:=\theta_j-\alpha\sum\limits_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$

$$\theta:=\theta-\frac{\alpha}{m}X^T(g(X\theta)-\overrightarrow{y})$$

使用特征缩放也可以使得收敛速度加快，很多特点都和线性回归相似，这里不再赘述。

## Advanced Optimization

实际上梯度下降中我们只需要计算导数项，将导数项插入到计算式中进行计算就可以了，但是如果需要监控收敛性我们可能需要自己写代码来完成。除了梯度下降法以外，实际上还有其他优化方法，例如

- Conjugate gradient
- BFGS
- L-BFGS

这些方法更加复杂更加高级，以后等我学会了再来更吧（咕咕咕）

目前来看这些算法有一定的优势，例如不需要人为选择学习率（实际上是自动选择的），运算速度也普遍比梯度下降要快得多，但是他们学起来也比较困难，可能需要好几天或好几周的时间进行学习。

*吴恩达：我都用了十多年了才知道这个算法在干啥*

这些算法也不建议自己进行编写，效率上和准确度上都会有偏差。

## Multiclass Classification

如果使用二元分类的方法进行多分类，我们可以采用的手段是将用例拆分，例如三分类的问题，我们可以拆分成为三个二分类问题。用这样的手段可以拟合三个分类器，那么每输入一个新数值，我们就能把这个数值带入三个分类器中，同时运行三个分类器，通过其概率的输出来判断结果属于哪个分类器。

##Overfitting

过拟合问题是一个常见问题，会导致我们的训练结果出现较大偏差。这个和欠拟合是一个对应的问题。

对于同样的数据集，如果我们使用不同的模型，就有可能导致不同的结果，如下图，拟合这个数据集，如果使用直线进行操作，那么很有可能导致欠拟合问题。但如果采用超级多的特征，我们会发现这个结果的Cost很小很小，拟合结果经过了所有点。这一定是一个完美的结果吗？至少看起来不如使用二次拟合的结果，这样的结果就是过拟合（或说是高方差）。

![OverFittingI](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/OverFittingIII.png)

不过学过多项式级数应当对函数拟合有一定了解，理论上多项式可以拟合符合要求的所有函数，所以使用超级多特征量，并且我们没有足够多的数据的时候就很有可能导致这种拟合问题的出现。我们说，过拟合的模型没有**泛化**能力，当面对训练样本以外的数据的时候，就会表现出拟合效果过差的现象。

统计学习中关于泛化的描述涉及很多十分复杂的运算，我们可以说，在目前的数学方法中，想要对一般的假设空间找到泛化误差界是很困难的，这里并不作介绍（当然我本人也并不会）。

在逻辑回归的时候也会出现相似的现象。

![OverFittingII](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/OverFittingII.png)

对于简单的回归问题我们通过画图就能解决大部分欠拟合或过拟合问题，可以直接确定使用什么样的模型最为合适。常见的解决过拟合的方案有以下两种

1. 手动的减少特征量。我们可以手动选择看起来更有用的变量，筛除看起来没有什么用的变量。实际上也可以使用算法进行自动选择。后者有时更加有效。
2. 正则化（Regularization）。我们保留所有的特征量，但降低参数$$\theta_j​$$的数量级。这个在后面会说到，当我们不愿意删除特征量的时候会使用。

## Regularization

这里要简介一下正则化。为了解决过拟合问题，我们要使用正则化。

统计学习中对正则化做了这样的说明，即正则化是结构风险最小化策略的实现，是在经验风险中增加正则化项（惩罚项）。我们一般认为正则化项是模型复杂度的单调递增函数，模型越复杂，一般就要设计越大的正则化项。常见的正则化项是模型参数向量的范数。前面说到，增加了正则化项的损失函数有如下形式

$$\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))+\lambda J(f)$$

其中前者为经验风险，后者为正则化项，$$\lambda$$负责调整两者之间的数量级关系。回归问题中的损失函数常用平方损失函数，正则化项就可以使用参数向量的$$L_2$$范数

$$L(\omega)=\frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x_i))+\frac{\lambda}{2}\left\|w\right\|^2$$

我们说$$w$$是参数向量，即前面一直使用的$$\theta$$。而一般说的$$L_n$$范数是

$$\left\|x\right\|_n=\left ( \sum\limits_{i=1}^n |x_i|^n \right )^{\frac{1}{n}}$$

一般还是更多人称为p-范数（p norm）。

除此之外还有交叉验证的方式。如果给出的样本数据充足，我们常将样本数据集切分为三部分，训练集（最大部分数据集，training set），验证集（validation set）和测试集（test set）。训练集用于训练我们的模型，但是要进过验证集来进行选择，并使用测试集进行测试评估模型的效果。在训练出的模型中，选择出训练集中误差最小的模型，再通过测试集评估效果。当实际应用中可能并不会有足够的数据给我们使用，所以就要使用一定的技巧进行计算，例如**交叉验证**（cross validation）。简单的交叉验证方式是取$$70%$$的数据为训练集，取$$30%$$数据集为测试集，通过测试集进行测试。有一类叫做S折交叉验证，将数据集随机等分为S个互不相交的子集，然后利用$$S-1$$个子集用于训练集，余下的一个用于测试集。将这个过程进行$$S$$次重复（一共有S种可能的组合），选出S次中估计中，误差最小的模型。如果给定数据集容量很小，$$S=N$$，这种方法被称为留一验证法。

---

假设我们遇到的问题是这样的

![Regularization](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/RegularizationI.png)

我们的优化项可能是

$$min_\theta \frac{1}{2m}\sum\limits_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2$$

我们对它进行一定的修改，例如加入若干项为

$$min_\theta \frac{1}{2m}\sum\limits_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+1000\theta_3^2+1000\theta_4^2$$

这时如果对函数进行最小化优化，我们的算法将不得不把$$\theta_3$$和$$\theta_4$$的值计算的非常小，以至于接近$$0$$，来保证这个损失函数达到最小值。这里我们“惩罚”了$$\theta_3$$和$$\theta_4$$，使这两个项接近零，我们实际上使得原模型变得简单了，即退化成了普通的二次模型。惩罚部分参数的目的也就是活得更简单的模型，而更简单的模型就不那么容易发生过拟合问题。

有时候我们有很多很多的特征，这时候我们并不知道要对哪些特征进行正则化，此时我们就需要对所有项进行这个操作，即

$$min_\theta \frac{1}{2m}\sum\limits_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum\limits_{i=1}^n\theta_j^2$$

这个正则项会使得所有项都进行一定程度的缩小。当然$$\theta_0$$不在惩罚列表中，所以这一项是大的。不过$$\theta_0$$这一项确实对其他特征没有什么影响，只是一个单独的偏置项而已。最终是否对这一项进行惩罚，其实影响微乎其微（话说回来$$\theta_0$$这一项根本就没有梯度，怎么会被优化呢。。。）。

$$\lambda$$的取值，如果不做什么考虑的话，只要是一个非负数就好，具体大小视情况而定，是一个超参数。

---

对于上面的线性回归的示例，如果我们采用了正则化项，其损失函数将变成

$$J(\theta)=\frac{1}{2m}\left[ \sum\limits_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum\limits_{i=1}^n\theta_j^2\right]$$

在求导后我们发现，对于$$\theta_0$$来说，梯度并没有改变，改变的只是其他$$\theta_j$$的梯度。求导后的梯度为

$$\theta_j:=\theta_j(1-\frac{\lambda}{m})-\alpha\frac{1}{m}\sum\limits_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$

注意$$(1-\frac{\lambda}{m})$$这一项，往往是一个十分接近但小于$$1$$的数字，而后面那一项和前面的推导是一样的，所以我们大概可以得到，梯度项的主要改变就是$$\theta_j$$略有缩小。这导致了所有$$\theta_j$$的梯度都发生了一定程度的减小。

---

对于逻辑回归的示例，我们可以将损失函数改写成

$$J(\theta)=-\left [\frac{1}{m}\sum\limits_{i=1}^my^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))\right ]+\frac{\lambda}{2m} \sum\limits_{i=1}^n\theta_j^2$$

用相似的方法还是可以得到相似的结果

---

吴恩达老师在Coursera里面贱贱地笑着说你们已经掌握了很多了（笑）

无论如何**线性回归**和**逻辑回归**这一部分知识的简单介绍就是这些了。



======================================================================

======================================================================

======================================================================



## Perceptron

感知机是一个简单的线性二分类模型。假设输入空间是$$\chi \subseteq \mathbb{R}$$，输出空间$$\gamma \subseteq  \left\{ -1,+1 \right\}$$，那么对于$$x\in\chi$$，$$y\in\gamma$$的输入输出，以下模型被称为感知机

$$f(x)=sign(w\cdot x+b)$$

$$w$$和$$b$$被称为模型参数，前者一般被称为权重（weight），后者一般被称为偏置（bias）。sign是取符号函数。

感知机是一个线性分类模型，以下为如何理解线性的问题

从直线开始，二维平面上的线性可分数据集$$T=\left \{ (x_1,y_1),(x_2,y_2),(x_3,y_3),...,(x_n,y_n) \right \}$$是二维平面上的点。其中的$$x_i$$可以是向量，但是此处去为一维向量方便理解。既然数据集是可分的，那必然能得到一条直线将数据分开。注意，当我们选择的点在直线上的时候

$$w\cdot x+b=0$$

当我们选择的点在直线的两侧的时候，这个值分别是正或负的。

既然如此，我们就可以通过他的符号来判断数据在直线的哪个位置。数据集中仍然有$$\gamma \subseteq  \left\{ -1,+1 \right\}$$，这就是给我们的参考，告诉我们哪些点分别在直线的哪边。相同的类比方式可以推广到三位空间中的情况，这时我们的$$w\cdot x+b=0$$实际上代表了一个平面，$$w$$是平面的法向量，$$b$$是截距。实际上，类似的结论可以向更高（无穷）维推广，这时的“平面”被称为超平面。超平面仍然满足我们定下的若干规则，因此也可以使用。常见分类问题经常是高维度的问题。

一般的，线性可分集中的超平面分类解是不唯一的。如果使用感知机进行分类，首先需要定义一个损失函数，让优化器最小化这个数值来达到优化效果。我们很容易想到的是，使用分类错误的点数来作为损失函数，优化至0的过程就是降低损失的过程。但是使用这个函数很难进行求导和优化，所以我们采用另一种方式。

首先要找到是哪些点分类错误。用$$w\cdot x_i+b$$的值与$$y_i$$进行比较，符号相同就是分类正确，否则就是分类错误，即对于分类错误的数据来说，

$$-y_i(w\cdot x_i+b)>0$$

我们将分类错误的点送入集合M中。而分类错误的点到超平面的距离为

$$-\frac{1}{\left\| w \right\|}\sum\limits_{x_i\in M}y_i(w\cdot x+b)$$

不考虑常数项系数，我们就得到了损失函数（经验风险函数）

$$L(w,b)=-\sum\limits_{x_i\in M}y_i(w\cdot x+b)$$

如果没有误分类的点，这个值将是0。该函数利用数值间的关系巧妙避免了绝对值函数的出现，便于求导进行优化。而学习过程也一般是BGD或SGD，其区别之后会提到。

我们对损失函数进行求导，得到

$$\triangledown_wL(w,b)=-\sum\limits_{x_i\in M}y_ix_i$$

$$\triangledown_b L(w,b)=-\sum\limits_{x_i\in M}y_i$$

那么对于一定大小的学习速率$$\alpha$$，参数更新为

$$w:=w+\alpha y_ix_i$$

$$b:=b+\alpha y_i$$

在线性可分数据集中，这个结果是必定收敛的

感知机的算法存在一种对偶的形式，有机会再进行描述。

[这个是一个感知机的代码](https://raw.githubusercontent.com/psycholsc/psycholsc.github.io/master/assets/tempsrc/Perceptron.py)

## Generalized Linear Model

广义线性模型。我们前面讲到的回归模型，它的$$y$$服从高斯分布。

首先介绍为什么服从高斯分布。我们假设线性回归的模型是

$$y^{(i)}=\theta^Tx^{(i)}+\epsilon^{(i)}$$

我们此处使用$$\epsilon$$作为对未知统计情况的预测，这个未知的条件可能是某些没有被建模的特征量，也有可能是随机噪声。我们对于这样的独立同分布的未建模影响做估计时，总会假设这一类影响服从正态分布，即可以认为

$$p(\epsilon^{(i)})=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(\epsilon^{(i)})^2}{2\sigma^2}}$$

我们根据上面的推测就可以认为$$y^{(i)}-\theta^Tx^{(i)}$$是服从正态分布的，则由于$$x$$是已知的，那么

$$p(y^{(i)}|x^{(i)};\theta)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}}$$

我们说，$$y$$是服从正态分布的。

而对于分类问题，$$y$$是服从伯努利分布（即只有两点的二项分布，也成为两点分布）的。两者服从不同的分布，对于解决问题来说其实还有一点复杂。实际上，我们可以认为，存在一种分布模型可以将他们统一，这种分布模型是指数分布族，

$$p(y;\eta)=b(y)e^{\eta^TT(y)-a(\eta)}$$

通过这个分布中的不同函数与参数的取值，我们不仅可以将两种分布统一，还能推广到更多问题上。首先对于伯努利分布

$$p(y;\Phi)=\Phi^y(1-\Phi)^{1-y}$$

我们取（将原分布律凑成需要的形式后取值）

$$T(y)=y$$

$$\begin{align*} a(\eta)  &= log(1-\Phi) \\  &= log(1+e^\eta) \end{align*}$$

$$b(y)=1$$

对于高斯分布

$$p(y;\mu)=\frac{1}{\sqrt{2\pi}}e^{-\frac{(y-\mu)^2}{2}}$$

我们取

$$\eta=\mu$$

$$T(y)=y$$

$$\begin{align*} a(\eta)  &= \frac{\mu^2}{2} \\  &= \frac{\eta^2}{2} \end{align*}$$

$$b(y)=\frac{1}{\sqrt{2\pi}}e^{-\frac{y^2}{2}}$$

通过不同的取值，我们可以组合得到不同的分布律。注释上面分布律括号内的参数是期望。使用广义线性模型的时候，例如逻辑回归（即二分类问题）中，我们有

$$h_\theta(x)=0\cdot p(y=0|x;\theta)+1\cdot p(y=1|x;\theta)=E[y|x;\theta]=\Phi=\frac{1}{1+e^{-\theta^Tx}}$$

在回归模型中，同理

$$h_\theta(x)=E[y|x;\theta]=\mu=\eta=\theta^Tx$$

这两个模型分别对应线性回归和逻辑回归，如果将问题推广到多项式回归（多分类模型）上，我们使用相同的方法，经过复杂的推导，可以得到Softmax的表达式。

## K-NN

K-Nearest Neighbor，K近邻算法，是一种简单的分类与回归方法。其输入为需要分类的特征向量，对应为特种空间的点，输出为所属类别。这类算法没有显式的学习过程，实际上只是利用训练数据集对数据进行类别的划分。

根据一个简洁的说法，K近邻算法是，给定一个训练数据集，对于一个新的输入，在训练数据集中找到K个与该实例最近邻的实例，如果这K个实例中大多数的实例从属于同一个类别A，我们就认为这个新输入属于这个A类别。

根据这个简单的描述，实际上就没有必要进行更多的说明了，算法也可以通过这种方式得出了。这里介绍一下常见的距离函数。使用不同的距离函数，得到的结果也是不一样的。常用的距离函数就是p-范数距离函数，前面介绍过，p-范数是

$$\left\|x\right\|_p=\left ( \sum\limits_{i=1}^p |x_i|^p \right )^{\frac{1}{p}}$$

其中$$p\ge 1$$。当p取1的时候，这个式子等价为直线上的绝对距离，即

$$L=\sum\limits_{i=1}^p |x-x_i|$$

当p取2的时候，这个距离等价为平面上的距离，即

$$L=\left ( \sum\limits_{i=1}^2 |x-x_i|^2 \right )^{\frac{1}{2}}$$

另一个常见的取值是$$\infty$$，此时该距离函数等价为取最大值。

关于K值的选择，也的确会对结果产生一定的影响。当K取值过大，例如K=N的时候，我们对于新加入的输出，会完全预测为所有分类中最大的那一类，而当K过小的时候，就只会对较小的局部进行分析，容易出现过拟合。当K=1的时候，算法退化为最近邻算法，是K近邻的一个特例。

有关K近邻算法的实现，往往采用kd树的方法。如果数据集比较大，对每一个数据都进行比较的话就会变得很慢，因此采用kd树的方法。使用Python的sklearn等库文件可以避免手写kd树。

首先对数据集进行按某个特征的平分，例如对特征$$x^{(1)}$$，将对应的特征$$x^{(1)}$$的所有数据中的中位数找出，并将整个样本空间使用一个超平面分解为两个空间，特征$$x^{(1)}$$的中位数处在这个超平面上。对于比中位数小的那部分空间，子节点的左节点将是这个空间，则右节点的空间就是比特征$$x^{(1)}$$中位数大的部分空间。换下一个特征$$x^{(2)}$$，按照这个特征进行分解，按同样的方式获得深度为2的子节点。循环下去直到不可分割，我们就生成了kd树。而使用kd树的最邻近搜索是，首先按照树搜索，从根节点开始搜索到最邻近的节点，并将最邻近节点的距离设定为最短距离。一步一步向上搜索，直到搜索到根节点，检验最近的位置。这样的搜索往往会减少半数以上的搜索点数。

## Naive Bayes



{% if page.comments %}
<div id="container"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">

<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
var gitment = new Gitment({
  id: '21', // 可选
  owner: 'psycholsc',
  repo: 'temp',
  oauth: {
    client_id: '9183e7259ea6d850a7df',
    client_secret: 'd0a82473ca685629b50ded0553f402b6ba2b2dee',
  },
})
gitment.render('container')
</script>
{% endif %}